{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e54dc55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "03073911",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d3d6173f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! open_api_key is not default parameter.\n",
      "                    open_api_key was transferred to model_kwargs.\n",
      "                    Please confirm that open_api_key is what you intended.\n"
     ]
    },
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for ChatOpenAI\n__root__\n  Did not find openai_api_key, please add an environment variable `OPENAI_API_KEY` which contains it, or pass  `openai_api_key` as a named parameter. (type=value_error)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m chat \u001b[38;5;241m=\u001b[39m ChatOpenAI(open_api_key \u001b[38;5;241m=\u001b[39m api_key)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\langchain\\load\\serializable.py:74\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 74\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lc_kwargs \u001b[38;5;241m=\u001b[39m kwargs\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pydantic\\v1\\main.py:341\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[1;34m(__pydantic_self__, **data)\u001b[0m\n\u001b[0;32m    339\u001b[0m values, fields_set, validation_error \u001b[38;5;241m=\u001b[39m validate_model(__pydantic_self__\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m, data)\n\u001b[0;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validation_error:\n\u001b[1;32m--> 341\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m validation_error\n\u001b[0;32m    342\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    343\u001b[0m     object_setattr(__pydantic_self__, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__dict__\u001b[39m\u001b[38;5;124m'\u001b[39m, values)\n",
      "\u001b[1;31mValidationError\u001b[0m: 1 validation error for ChatOpenAI\n__root__\n  Did not find openai_api_key, please add an environment variable `OPENAI_API_KEY` which contains it, or pass  `openai_api_key` as a named parameter. (type=value_error)"
     ]
    }
   ],
   "source": [
    "chat = ChatOpenAI(open_api_key = api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240825e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #earlier we were doing\n",
    "# llm = OpenAI(openai_api_key = api_key)\n",
    "# llm.generate('here is a fact about pluto:')\n",
    "# #this ompletes the answer i.e Autocompletion giving a string with the fact\n",
    "\n",
    "# #we cant do \n",
    "# Chat(\"tell me about pluto\")\n",
    "# #we cant pass string for autocompletion u have to give it in a format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893a619a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import AIMessage, HumanMessage, SystemMessage\n",
    "#defualt Message -> you are a helpful assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01196e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = chat([HumanMessage(Content= \"tell me a fact about pluto\")])\n",
    "#paaing a list of message -> which has content "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae489b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969df252",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175f0311",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = chat([SystemMessage(Content= \"you are a lazy teenager who wants to party\")\n",
    "    ,HumanMessage(Content= \"tell me a fact about pluto\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e009ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat.generate ([SystemMessage(Content= \"you are a lazy teenager who wants to party\")\n",
    "                ,HumanMessage(Content= \"tell me a fact about pluto\")],\n",
    "               [SystemMessage(Content= \"you are friendly Assistant\")\n",
    "                ,HumanMessage(Content= \"tell me a fact about Mars\")])\n",
    "#generate a list of responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c489a694",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.llm_output # gives the details "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47176364",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.generations #to see the genrations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11e30e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.generation[0][0].text #filtering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "acd261cf",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'chat' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m result\u001b[38;5;241m=\u001b[39m chat([SystemMessage(Content\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou are friendly Assistant\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m                 ,HumanMessage(Content\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtell me a fact about Mars\u001b[39m\u001b[38;5;124m\"\u001b[39m)], temperature \u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,presence_penalty \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m, Max_token\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'chat' is not defined"
     ]
    }
   ],
   "source": [
    "result= chat([SystemMessage(Content= \"you are friendly Assistant\"),\n",
    "              HumanMessage(Content= \"tell me a fact about Mars\")],\n",
    "             temperature =2, presence_penalty = 2, Max_token=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d176dbce",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'Langchain'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mLangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcache\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InMemoryCache\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'Langchain'"
     ]
    }
   ],
   "source": [
    "import langchain\n",
    "from Langchain.cache import InMemoryCache\n",
    "langchain.llm_cache = InMemoryCache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7d5856",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
